<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Kafka（上）知识点速览</title>
    <link href="/2022/04/02/Kafka%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%A7%88%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2022/04/02/Kafka%E7%9F%A5%E8%AF%86%E7%82%B9%E9%80%9F%E8%A7%88%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="Kafka（上）知识点速览"><a href="#Kafka（上）知识点速览" class="headerlink" title="Kafka（上）知识点速览"></a>Kafka（上）知识点速览</h1><p>​    该文是本人在学习Kafka过程中对知识检索后的总结笔记，大部分内容相对简要，适合速览回忆，部分重点内容如需深入理解时，会列出相关所搜集的更为详细的资料引用。</p><h2 id="1-MQ"><a href="#1-MQ" class="headerlink" title="1. MQ"></a>1. MQ</h2><h3 id="1-1-消息中间件的作用"><a href="#1-1-消息中间件的作用" class="headerlink" title="1.1 消息中间件的作用"></a>1.1 消息中间件的作用</h3><ol><li><p>消息传递</p></li><li><p>系统解耦</p><p>系统耦合较高时通过消息中间件解耦，从而单个系统不需考虑其他系统调用失败，网络情况，其余系统通过消费消息处理业务；除此之外，通过消息中间件各系统通过不同编程语言实现</p></li><li><p>削峰限流</p><p>将系统的超量请求暂存其中，以便系统后期可以慢慢进行处理，从而避免了请求的丢失或系统被压垮。</p></li><li><p>异步调用</p><p>上游系统对下游系统的调用若为同步调用，则会大大降低系统的吞吐量与并发度，且系统耦合度太高。而异步调用则会解决这些问题。所以两层之间若要实现由同步到异步的转化，一般性做法就是，在这两层间添加一个MQ层。</p></li><li><p>数据流</p><p>分布式系统中用户会操作多久都是没法预测的，消息系列通过消息被处理的频率，来方便的辅助确定那些表现不佳的处理过程或领域</p></li></ol><h3 id="1-2-分类"><a href="#1-2-分类" class="headerlink" title="1.2 分类"></a>1.2 分类</h3><ol><li><p>点对点</p><p>消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息，消费之后queue中就不再有该消息，即只能有一个消费者消费。</p></li><li><p>发布订阅    </p><p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。</p></li></ol><h3 id="1-3-常见消息中间件对比"><a href="#1-3-常见消息中间件对比" class="headerlink" title="1.3 常见消息中间件对比"></a>1.3 常见消息中间件对比</h3><table><thead><tr><th>关键词</th><th>ACTIVEMQ</th><th>RABBITMQ</th><th>KAFKA</th><th>ROCKETMQ</th></tr></thead><tbody><tr><td>开发语言</td><td>Java</td><td>ErLang</td><td>Java</td><td>Java</td></tr><tr><td>单机吞吐量</td><td>万级</td><td>万级</td><td>十万级</td><td>十万级</td></tr><tr><td>Topic</td><td>-</td><td>-</td><td>百级Topic时会影响系统吞吐量</td><td>千级Topic时会影响系统吞吐</td></tr><tr><td>社区活跃度</td><td>低</td><td>高</td><td>高</td><td>高</td></tr></tbody></table><ol><li><p>Kafka</p><p>不支持延时队列、死信队列等特性；具有消息持久化、高吞吐率的特点；常用于大数据领域的实时计算、日志采集等场景。一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式 开放给各种consumer，例如hadoop、Hbase、Solr等。 消息系统：解耦和生产者和消费者、缓存消息等。 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网⻚、 搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过 订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖 掘。 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产 各种操作的集中反馈，比如报警和报告。</p></li><li><p>RocketMQ</p><p>性能与稳定性非常高，支持延时队列、死信队列，&#x3D;&#x3D;相对Kafka更适用于电商等场景。&#x3D;&#x3D;</p></li></ol><h2 id="2-Kafka概述"><a href="#2-Kafka概述" class="headerlink" title="2. Kafka概述"></a>2. Kafka概述</h2><h3 id="2-1-Kafka的特点"><a href="#2-1-Kafka的特点" class="headerlink" title="2.1 Kafka的特点"></a>2.1 Kafka的特点</h3><ol><li><p><strong>高吞吐量</strong></p><p>即使是非常普通的硬件kafka也可以支持每秒数十万的消息。</p><blockquote><p>面试题引申：为什么Kafka有那么大的吞吐率？</p><p>Reference: <a href="https://zhuanlan.zhihu.com/p/120967989">https://zhuanlan.zhihu.com/p/120967989</a></p><ol><li><p>磁盘顺序读写（重点）</p><p>我们知道，磁盘IO分为随机读写与顺序读写，磁盘读写时间 &#x3D; 寻找磁道+寻找扇面+读写数据操作的时间，其中随机读写耗时更高</p></li><li><p>零拷贝（重点）</p><p>a. 正常数据复制流程:<br>磁盘文件-&gt;内核缓冲区-&gt;用户缓冲区-&gt;socket缓冲区-&gt;网卡-&gt;消费者</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204012234562.png" alt="磁盘IO" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204012234811.png" alt="网络IO示例" style="zoom:50%;" /><p>b. Kafka的零拷贝流程：</p><p>​    kafka:磁盘文件-&gt;内核缓冲区-&gt;网卡-&gt;消费者</p><p>Linux网络IO详解，Reference: <a href="https://juejin.cn/post/7076743627354931213">https://juejin.cn/post/7076743627354931213</a></p></li><li><p>数据采用partition进行多分区存储（重点）</p></li><li><p>批量压缩数据，减少带宽消耗</p></li></ol></blockquote></li><li><p><strong>持久化消息</strong></p><p>Kafka的消息是持久化的硬盘上的，其持久化机制将在后续介绍</p></li><li><p><strong>订阅-发布模式，由消费者主动拉取消息</strong></p><blockquote><p>（引申）主动拉取消息的好处：</p><ul><li>简化kafka设计，降低了难度。</li><li>Consumer根据消费能力自主控制消息拉取速度。（重点）</li><li>consumer根据自身情况自主选择消费模式，例如批量，重复消费，从制定partition或位置(offset)开始消费等。（重点）</li></ul></blockquote></li><li><p><strong>消费状态保存在客户端</strong></p></li><li><p><strong>支持同步和异步复制两种HA</strong></p></li></ol><h3 id="2-2-Kafka订阅发布结构"><a href="#2-2-Kafka订阅发布结构" class="headerlink" title="2.2 Kafka订阅发布结构"></a>2.2 Kafka订阅发布结构</h3><p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204012359519.png" alt="Kafka结构"></p><ol><li><p>Producer</p></li><li><p>Consumer</p></li><li><p>Consumer Group</p><p>每个Consumer属于⼀个特定的Consumer Group，⼀条消息可以被多个不同的Consumer Group消费，但是⼀个Consumer Group中只能有⼀个Consumer能够消费该消息</p><p>每个Consumer Group都存在一个的leader与follower，leader在特定时机进行选举出来，选举机制会在后续说明，leader负责管理各consumer在rebalence后partion的分配</p></li><li><p>Topic</p></li><li><p>Broker</p><ul><li><p>⼀个Kafka节点就是⼀个broker，⼀个或者多个Broker可以组成⼀个Kafka集群</p><p>理解简单点：运行一个Kafka进程的服务器节点</p></li><li><p>对于一个topic，可以通过多partition的方式存放在不同broker之中，同时broker内保有不同partiton的副本，该内容将在后续3.2小节进行详细介绍</p></li><li><p>服务端(brokers)和客户端(producer、consumer)之间通信通过 <strong>TCP协议</strong> 来完成</p></li></ul></li><li><p>Partition</p><p>物理上的概念，⼀个topic可以分为多个partition，每个partition内部消息是有序的</p><blockquote><p>引申面试题：</p><p>a. Patition与Broker的数量关系</p><p>​    i. 如果Partition数等于Broker数，Kafka集群将比较均衡<br>​    ii. 如果Partition数小于Broker数<br>​    某个Broker节点上不存在当前topic的分区，Broker节点可能被闲置！最终导致Kafka集群吞吐率下降<br>​    iii. 如果Partition数大于Broker数<br>​    抛异常：java.lang.IllegalArgumentException: Invalid partition given with record: 1 is not in the range [0…0].</p><p>b. Consumer与Broker的关系</p><p>​    topic下的一个分区只能被同一个consumer group下的一个consumer线程来消费，所以应该小于等于partition</p><p>​    如果你的分区数是N，那么最好线程数也保持为N，这样通常能够达到最大的吞吐量。超过N的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。</p></blockquote></li><li><p>Offset(位移量)</p><ul><li><p>用以标记消费进度。</p></li><li><p>其更新受到了高低水位（用以保证一致性）影响，Kafka 0.9之前，基于Zookeeper来存储Partition的Offset信息，0.9之后采取的是Group Coordinator来记录各Partition的offset</p></li><li><p>提交方式</p><ul><li>Auto-commit</li><li>手动提交</li></ul></li></ul></li></ol><h3 id="2-3-Kafka持久化"><a href="#2-3-Kafka持久化" class="headerlink" title="2.3 Kafka持久化"></a>2.3 Kafka持久化</h3><blockquote><p>如果需要详细深入理解，请参照以下博客，本博客的内容结尾较为简短的概要</p><p>Reference:</p><ol><li>消息持久化理论基础：<a href="https://www.jianshu.com/p/8a4154780204">https://www.jianshu.com/p/8a4154780204</a></li><li>消息持久化实际文件如何对应？：<a href="https://blog.csdn.net/weixin_38653290/article/details/86621811?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.baidujs&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.baidujs">https://blog.csdn.net/weixin_38653290/article/details/86621811?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.baidujs&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-1.baidujs</a></li></ol></blockquote><ol><li><p>持久化写入方式：顺序IO</p></li><li><p>持久化数据结构</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204020141289.png" alt="kafka持久化数据结构" style="zoom: 50%;" /><ul><li>kafka每个partion的数据按照Segment File进行切分</li><li>每个Segment文件可以分为<code>.index</code>文件与<code>.log</code>文件<ul><li><code>.index</code>文件格式如下，由(offset, 物理地址)构成，其中offset代表parition全局中消息第?条</li><li><code>.data</code>文件由多个Message组成，Message有着自己的数据结构</li></ul></li></ul></li><li><p>日志清理</p><p>使用久了，文件大小会逐渐过大，因此有持久化文件的清除策略：</p><p>a. 超过指定时间清理</p><p>b. 超过指定大小则被删除</p><p>如何清理日志：</p><p>定期扫描，按照设置的清理策略直接删除Segment文件</p></li><li><p>日志压缩策略</p><p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204020136035.png" alt="kafka压缩策略"></p><p>对于重复的&lt;K, V&gt;，取最大的offset进行合并，删除较小的offset数据</p></li></ol><h3 id="2-4-Producer"><a href="#2-4-Producer" class="headerlink" title="2.4 Producer"></a>2.4 Producer</h3><ol><li><p><strong>Kafka生产者客户端架构与处理流程</strong></p><blockquote><p>Reference: <a href="https://blog.csdn.net/LeoHan163/article/details/105902707">https://blog.csdn.net/LeoHan163/article/details/105902707</a></p></blockquote><div align="center">        <img src="../../../../../Downloads/chrome/处理流程.png" alt="处理流程" style="zoom:67%;">  </div></li><li><p><strong>批量发送</strong></p><p>由2.4.1可知，消息是通过消息累加器向缓冲区发送消息并进行叠加，然后再批量发送，因此影响批量发送的有两个因素</p><p>a. <code>spring.kafka.producer.batch-size</code>缓冲区batch大小</p><p>b. <code>spring.kafka.producer.properties.linger.ms</code>(保留时间)</p><p>当缓冲区大于缓冲区设置batch大小就会批量发送，如果消息一直小于batch大小，超过linger.ms也会发送</p></li><li><p><strong>&#x3D;&#x3D;Producer如何与Broker通信&#x3D;&#x3D;</strong></p></li><li><p><strong>分区策略</strong></p><ol><li><p>Randmness</p><p>随机发送</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021132913.png" alt="随机策略" style="zoom:33%;" /></li><li><p>RoundRobin</p><p>Producer按照顺序轮流向Partition发送消息</p><p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021128991.svg" alt="RoundRobin"></p></li><li><p>按消息键保序策略</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021133516.png" alt="按键保序" style="zoom:33%;" /><blockquote><p>Reference: <a href="https://juejin.cn/post/6959841646330511373">https://juejin.cn/post/6959841646330511373</a></p></blockquote></li></ol></li></ol><h3 id="2-5-Consumer-x2F-Consumer-Group"><a href="#2-5-Consumer-x2F-Consumer-Group" class="headerlink" title="2.5 Consumer &#x2F; Consumer Group"></a>2.5 Consumer &#x2F; Consumer Group</h3><ol><li><p><strong>各消费者partiton消费offset的更新方法</strong></p><p>1)0.9之前是zookeeper保有各consumer的membership与offset</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021156170.png" alt="image-20220402115624113" style="zoom: 25%;" /><p>2)0.9之后是则又zookeeper变为Group Coordinator进行管理与更新</p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021157999.png" alt="image-20220402115758945" style="zoom:25%;" /></li><li><p><strong>Coordinator</strong></p><ul><li>Group Coordinator 是一个服务，每个 Broker在启动的时候都会启动一个该服务。</li><li>Group Coordinator 的作用是用来存储 Group 的相关 Meta 信息，并将对应 Partition 的 Offset 信息记录到 Kafka 内置Topic中。</li><li>kafka 在 0.9 之前是基于 Zookeeper 来存储 Partition 的 Offset 信息</li></ul><p>如何确定Coordinator</p><ul><li><p>计算 Group 对应在 consumer_offsets 上的 Partition</p></li><li><p>根据对应的Partition寻找该Partition的leader所对应的Broker，该Broker上的Group Coordinator即就是该Group的Coordinator</p></li></ul></li><li><p><strong>Reblance</strong></p><p>a. 什么是Reblance？</p><p>由于某些原因导致Consumer的partiton重新分配</p><p>b. Reblance的时机？</p><ul><li><p>组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。</p><blockquote><p>引申：一般什么常见情况会导致组成员个数发生变化？</p><p>达到以下两种条件都会导致Consumer被踢出Consumer Group引发Rebalence</p><p>i. Consumer消费超过最大消费时间</p><p>​    出现场景：</p><p>​    例如消费者远程调用等待时间过长导致超过了消费时间</p><p>​    解决方案：</p><p>​    设置合适的max.poll.interval.ms</p><p>ii. Consumer超过最大心跳时间没有发送心跳</p><p>​    解决方案：</p><ul><li>设置 session.timeout.ms &#x3D; 6s。</li><li>设置 heartbeat.interval.ms &#x3D; 2s。</li><li>要保证 Consumer 实例在被判定为 “dead” 之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &gt;&#x3D; 3 * heartbeat.interval.ms。</li></ul></blockquote></li><li><p>订阅的 Topic 个数发生变化。</p></li><li><p>订阅 Topic 的分区数发生变化。</p></li></ul><p>c. Reblance会造成什么影响？</p><ul><li>数据重复消费: 消费过的数据由于提交offset任务也会失败，在partition被分配给其他消费者的时候，会造成重复消费，数据重复且增加集群压力</li><li>Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大</li><li>频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance</li><li>数据不能及时消费，会累积</li></ul><p>d. Reblance流程</p><ul><li>JoinGroup<ul><li>首先等待加入consumer加入group</li><li>如果原来的leader挂了，一般第一个申请加入的成为leader</li><li>等待leader分配分区</li></ul></li><li>SyncGroup<ul><li>leader根据rebalance策略分配分区（详细见2.5.4）</li></ul></li></ul></li></ol><blockquote><p>Reference: <a href="https://blog.csdn.net/qq_21383435/article/details/108720155">https://blog.csdn.net/qq_21383435/article/details/108720155</a></p></blockquote><blockquote><p>引申：</p><p>没有指定分区策略，怎么分配partion给consumer的？</p><ul><li>如果在发消息的时候指定了分区，则消息投递到指定的分区</li><li>如果没有指定分区，但是消息的key不为空，则基于key的哈希值来选择一个分区</li><li>如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区</li></ul></blockquote><ol start="4"><li><strong>分区策略</strong></li></ol><p>​    a. RoundRobin</p><p>​    与Producer的RoundRobin概念差不多</p><p>​    b. Range</p><p>​    如图：</p><p>​        i. Consumer分配数 &#x3D; 各topic partition总整 &#x2F; consumer总数</p><p>​        ii. Consumer额外分配数 &#x3D; 各topic partition总数 % consumer总数</p><p>​        iii. Consumer持有partition&#x3D; 分配数+额外分配数</p><p>​        iv. 依次按照topic顺序分配partition，直到Consumer持有partition数目达到iii</p><p><img src="https://raw.githubusercontent.com/RoyLMS/imageHost/master/202204021214234.svg" alt="kafkaRange"></p><p>​    c. Sticky</p><p>​    类似于round robin的分配方法，轮流分配，不同之处在于，尽可能均衡的将partition分配给consumer，各consumer最多相差1个；</p><p>​    同时Rebalence时也尽可能的保留现有分区，而不是完全重新分配，详细请参考[1]</p><p>​    三种方法中，Sticky最为均衡，但是一般默认的Range就足以</p><blockquote><p>Reference: </p><p>[1] 三种分区策略的优劣势比较：<a href="https://blog.csdn.net/CSDN_WYL2016/article/details/107629527">https://blog.csdn.net/CSDN_WYL2016/article/details/107629527</a></p><p>[2] RoundRoubin实现：<a href="https://www.cnblogs.com/AK47Sonic/p/8097890.html">Kafka0.11之RoundRobinPartitioner&#x2F;HashPartitioner</a></p></blockquote><h3 id="2-6Message"><a href="#2-6Message" class="headerlink" title="2.6Message"></a>2.6Message</h3><p>​    &#x3D;&#x3D;TODO: 待学习&#x3D;&#x3D;</p><h2 id="3-高可用-HA-机制"><a href="#3-高可用-HA-机制" class="headerlink" title="3. 高可用(HA)机制"></a>3. 高可用(HA)机制</h2><h3 id="3-1多副本机制与-ISR"><a href="#3-1多副本机制与-ISR" class="headerlink" title="3.1多副本机制与 ISR"></a>3.1多副本机制与 ISR</h3><p>​    a. 多副本机制</p><blockquote><p>1.Partition在多个broker中保留有replica（副本），通过多副本保存可以保证消息不丢失</p><p>2.这些partition中一个是Leader，其余为follower。Producer只与Leader交互，把数据写入到Leader中。</p><p>3.Followers从Leader中拉取数据进行数据同步</p><p>4.Consumer只从Leader拉取数据</p><p>这就是多副本机制，Kafka的多副本机制维护数据同步的步骤3是通过ISR机制来维护的。</p></blockquote><p>​    b. 名词解释</p><p>​        AR:全称 Assigned-Replicas，一个 Partition 对应的主从所有的 Partition 列表，AR &#x3D; ISR + OSR。</p><p>​        OSR: 全称 Out-Sync-Replicas，没有进行数据同步的从 Partition 列表，其中包括失效的从 Partition 和刚刚加入进来的新 Partition。处于 OSR 列表中的 Partition 不能够进行数据的同步操作。</p><p>​        ISR: 维持着数据同步的Partition列表</p><p>​    c. ISR</p><ul><li>kafka的消息同步不是完全同步，也不是完全异步，是一种特殊的ISR（In Sync Replica）</li><li>leader会维持一个与其保持同步的replica集合，该集合就是ISR，每一个partition都有一个ISR，它是由leader动态维护。</li><li>我们要保证kafka不丢失message，就要保证ISR这组集合存活（至少有一个存活），并且消息commit成功。</li><li>ISR管理者：leader</li></ul><p>​    d. ISR什么时候踢掉follower</p><p>​        i. 节点必须维护和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接，心跳超时就会被踢出去</p><p>​        ii. 如果节点是follower，它必要能及时同步与leader的写操作，不能延时太久。</p><p>​    e. Follower 如何追上Leader的数据？</p><p>​        Follower fetch leader数据，有两个参数决定是否能赶上</p><p>​        <code>eplica.lag.max.messages 落后的消息个数</code><br>​        <code>replica.lag.time.max.ms 多长时间没有发送FetchQuest请求拉去leader数据</code></p><p>​        比如落后消息达到设置的100，10s中没有再发送FetchRequest请求，就会从ISR列表中移除。</p><h3 id="3-2-Ack"><a href="#3-2-Ack" class="headerlink" title="3.2 Ack"></a>3.2 Ack</h3><p>​    Producer向Kafka集群发送消息，leader根据设置进行Ack返回确认消息是否送达</p><p>​    a. Ack &#x3D; 0</p><p>​        不论写入是否成功,server不需要给Producer发送Response</p><p>​    b. Ack &#x3D; 1</p><p>​        Leader写入成功后即发送Response</p><p>​    c. Ack &#x3D; -1</p><p>​        等待所有ISR接收到消息后再给Producer发送Response,这是最强保证</p><h3 id="3-3-高水位-HW"><a href="#3-3-高水位-HW" class="headerlink" title="3.3 高水位(HW)"></a>3.3 高水位(HW)</h3><ol><li><p>名词解释</p><ul><li><p>BaseOffset</p><p>起始位移，该副本中第一条消息的offset</p></li><li><p>HW</p><p>副本的高水印值，决定了消费者能消费的最新消息能到哪个offset</p></li><li><p>LEO</p><p>日志末端位移，代表日志文件中下一条待写入消息的offset</p></li><li><p>LSO</p><p>全称 Last-Stable-Offset，表示为 LSO 之前的消息都已经被确认，而在 LSO 之后的消息还未被确认，其主要被用于事务</p></li></ul></li><li><p>HW</p><ul><li>副本的高水印值，replica中leader副本和follower副本都会有这个值，通过它可以得知副本中已提交或已备份消息的范围，leader副本中的HW，决定了消费者能消费的最新消息能到哪个offset</li><li>如下图所示，HW值为8，代表offset为[0,8]的9条消息都可以被消费到，它们是对消费者可见的，而[9,12]这4条消息由于未提交，对消费者是不可见的。注意HW最多达到LEO值时</li></ul></li><li><p>如何更新HW</p><p>leader副本会比较自己的LEO以及满足条件的follower副本上的LEO，选取两者中较小值作为新的HW，来更新自己的HW值。</p></li><li><p>什么时候尝试更新HW</p><p>a.producer向leader写消息，会尝试更新。</p><p>b.leader处理follower的fetch请求，先读取log数据，然后尝试更新HW。</p><p>c.副本成为leader副本时，会尝试更新HW。</p><p>d.broker崩溃可能会波及leader副本，也需要尝试更新。</p></li></ol><h3 id="3-4-事务"><a href="#3-4-事务" class="headerlink" title="3.4. 事务"></a>3.4. 事务</h3><p>&#x3D;&#x3D;TODO: 待学习&#x3D;&#x3D;</p><blockquote><p>Reference: <a href="https://blog.csdn.net/u010002184/article/details/113933973#:~:text=Kafka%E4%BA%8B%E5%8A%A1%E7%89%B9,%E6%97%B6%E6%88%90%E5%8A%9F%E6%88%96%E8%80%85%E5%A4%B1%E8%B4%A5%E3%80%82">Kafka事务使用</a></p></blockquote><h3 id="3-5-避免重复消费-x2F-幂等性"><a href="#3-5-避免重复消费-x2F-幂等性" class="headerlink" title="3.5 避免重复消费 &#x2F; 幂等性"></a>3.5 避免重复消费 &#x2F; 幂等性</h3><p>​    Producer与leader通信是通过socket通信的，kafka为每条消息添加上了类似pid的唯一标识，这样ACK就带上一条消息的标识统一标识的消息反复发送是都只执行一次</p><h2 id="4-TODO"><a href="#4-TODO" class="headerlink" title="4. TODO"></a>4. TODO</h2><ul><li><input disabled="" type="checkbox"> 学习并补充2.6 Message</li><li><input disabled="" type="checkbox"> 学习并补充3.4Kafka事务</li><li><input disabled="" type="checkbox"> 学习并补充Kafka stream</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/03/30/hello-world/"/>
    <url>/2022/03/30/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
